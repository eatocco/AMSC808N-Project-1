{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from optimizers import GradientDescent, Nesterov, Adam,LBFGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train[(y_train == 1) | (y_train == 7)].reshape(\n",
    "    (-1, np.prod(X_train.shape[1:]))) / 255.\n",
    "y_train = 2 * (y_train[(y_train == 1) | (y_train == 7)] == 1) - 1\n",
    "X_test = X_test[(y_test == 1) | (y_test == 7)].reshape(\n",
    "    (-1, np.prod(X_test.shape[1:]))) / 255.\n",
    "y_test = 2 * (y_test[(y_test == 1) | (y_test == 7)] == 1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_20 = PCA(n_components=20)\n",
    "X_train_20 = pca_20.fit_transform(X_train)\n",
    "X_test_20 = pca_20.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13007, 421]) torch.Size([2163, 421])\n"
     ]
    }
   ],
   "source": [
    "def get_quadratic(X_data, y_data):\n",
    "    \n",
    "    quad_term = (X_data[:, :, np.newaxis] *\n",
    "                 X_data[:, np.newaxis, :]).reshape((len(X_data), -1))\n",
    "    quadratic = y_data[:, np.newaxis] * \\\n",
    "        np.hstack((quad_term, X_data, np.ones((len(X_data), 1))))\n",
    "    return quadratic.astype(np.float64)\n",
    "\n",
    "\n",
    "quad_train = torch.tensor(get_quadratic(X_train_20, y_train))\n",
    "quad_test = torch.tensor(get_quadratic(X_test_20, y_test))\n",
    "\n",
    "print(quad_train.size(), quad_test.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function over entire training set\n",
    "def loss_function(w, train_data, lam=1e-3):\n",
    "   # print(w.double().size())\n",
    "    \n",
    "    B = torch.matmul(-train_data, w).double()\n",
    "    return torch.sum(torch.log(1 + torch.exp(B.double()))) / len(train_data) + lam / 2 * torch.sum(w ** 2)\n",
    "\n",
    "# gradient function allows for different batches\n",
    "\n",
    "\n",
    "def loss_gradient(w, data_batch, lam=1e-3):\n",
    "    exp_quad = torch.exp(torch.matmul(-data_batch.double(),w.double()))\n",
    "    coef = exp_quad / (1 + exp_quad)\n",
    "    return torch.sum(-data_batch * coef[:, np.newaxis], axis=0) / len(data_batch) + lam * w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_test_func(w, train_data, test_data):\n",
    "\n",
    "   \n",
    "    eval_train = (torch.matmul(train_data,w) > 0)\n",
    "    eval_test = (torch.matmul(test_data, w) > 0)\n",
    "    \n",
    "    correct_train = torch.sum(eval_train)\n",
    "    correct_test = torch.sum(eval_test)\n",
    "    acc_train = correct_train / len(eval_train)\n",
    "    acc_test = correct_test / len(eval_test)\n",
    "    print(f'train correct: {correct_train}, train accuracy: {acc_train}')\n",
    "    print(f'test correct: {correct_test}, test accuracy: {acc_test}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  2 : loss =  tensor(14.2119)  gradnorm =  tensor(6.0377, dtype=torch.float64)\n",
      "Iter  3 : loss =  tensor(0.3508)  gradnorm =  tensor(1.3995, dtype=torch.float64)\n",
      "Iter  4 : loss =  tensor(0.7189)  gradnorm =  tensor(2.3331, dtype=torch.float64)\n",
      "Iter  5 : loss =  tensor(0.5194)  gradnorm =  tensor(2.7926, dtype=torch.float64)\n",
      "Iter  6 : loss =  tensor(0.6122)  gradnorm =  tensor(2.0289, dtype=torch.float64)\n",
      "Iter  7 : loss =  tensor(1.1263)  gradnorm =  tensor(1.8271, dtype=torch.float64)\n",
      "Iter  8 : loss =  tensor(0.2753)  gradnorm =  tensor(1.2959, dtype=torch.float64)\n",
      "Iter  9 : loss =  tensor(0.8178)  gradnorm =  tensor(0.9861, dtype=torch.float64)\n",
      "Iter  10 : loss =  tensor(0.0586)  gradnorm =  tensor(0.2176, dtype=torch.float64)\n",
      "Iter  11 : loss =  tensor(0.4209)  gradnorm =  tensor(2.5927, dtype=torch.float64)\n",
      "Iter  12 : loss =  tensor(51.5524)  gradnorm =  tensor(4.0791, dtype=torch.float64)\n",
      "Iter  13 : loss =  tensor(16.4640)  gradnorm =  tensor(1.8733, dtype=torch.float64)\n",
      "Iter  14 : loss =  tensor(4.6240)  gradnorm =  tensor(0.0962, dtype=torch.float64)\n",
      "Iter  15 : loss =  tensor(4.4473)  gradnorm =  tensor(0.0943, dtype=torch.float64)\n",
      "Iter  16 : loss =  tensor(4.2774)  gradnorm =  tensor(0.0925, dtype=torch.float64)\n",
      "Iter  17 : loss =  tensor(4.1140)  gradnorm =  tensor(0.0907, dtype=torch.float64)\n",
      "Iter  18 : loss =  tensor(3.9568)  gradnorm =  tensor(0.0890, dtype=torch.float64)\n",
      "Iter  19 : loss =  tensor(3.8056)  gradnorm =  tensor(0.0872, dtype=torch.float64)\n",
      "Iter  20 : loss =  tensor(3.6602)  gradnorm =  tensor(0.0856, dtype=torch.float64)\n",
      "Iter  21 : loss =  tensor(3.5203)  gradnorm =  tensor(0.0839, dtype=torch.float64)\n",
      "Iter  22 : loss =  tensor(41.2618)  gradnorm =  tensor(2.9459, dtype=torch.float64)\n",
      "Iter  23 : loss =  tensor(4.3123)  gradnorm =  tensor(0.0929, dtype=torch.float64)\n",
      "Iter  24 : loss =  tensor(4.1484)  gradnorm =  tensor(0.0911, dtype=torch.float64)\n",
      "Iter  25 : loss =  tensor(3.9908)  gradnorm =  tensor(0.0893, dtype=torch.float64)\n",
      "Iter  26 : loss =  tensor(3.8391)  gradnorm =  tensor(0.0876, dtype=torch.float64)\n",
      "Iter  27 : loss =  tensor(3.6932)  gradnorm =  tensor(0.0859, dtype=torch.float64)\n",
      "Iter  28 : loss =  tensor(3.5528)  gradnorm =  tensor(0.0843, dtype=torch.float64)\n",
      "Iter  29 : loss =  tensor(3.4178)  gradnorm =  tensor(0.0827, dtype=torch.float64)\n",
      "Iter  30 : loss =  tensor(3.2879)  gradnorm =  tensor(0.0811, dtype=torch.float64)\n",
      "Iter  31 : loss =  tensor(3.1629)  gradnorm =  tensor(0.0795, dtype=torch.float64)\n",
      "Iter  32 : loss =  tensor(10.4064)  gradnorm =  tensor(1.9534, dtype=torch.float64)\n",
      "Iter  33 : loss =  tensor(13.1412)  gradnorm =  tensor(2.9169, dtype=torch.float64)\n",
      "Iter  34 : loss =  tensor(34.9751)  gradnorm =  tensor(2.8676, dtype=torch.float64)\n",
      "Iter  35 : loss =  tensor(7.5390)  gradnorm =  tensor(0.7009, dtype=torch.float64)\n",
      "Iter  36 : loss =  tensor(6.0997)  gradnorm =  tensor(0.1105, dtype=torch.float64)\n",
      "Iter  37 : loss =  tensor(5.8668)  gradnorm =  tensor(0.1083, dtype=torch.float64)\n",
      "Iter  38 : loss =  tensor(5.6427)  gradnorm =  tensor(0.1062, dtype=torch.float64)\n",
      "Iter  39 : loss =  tensor(5.4272)  gradnorm =  tensor(0.1042, dtype=torch.float64)\n",
      "Iter  40 : loss =  tensor(5.2199)  gradnorm =  tensor(0.1022, dtype=torch.float64)\n",
      "Iter  41 : loss =  tensor(5.0205)  gradnorm =  tensor(0.1002, dtype=torch.float64)\n",
      "Iter  42 : loss =  tensor(15.9347)  gradnorm =  tensor(1.5237, dtype=torch.float64)\n",
      "Iter  43 : loss =  tensor(4.9263)  gradnorm =  tensor(0.0993, dtype=torch.float64)\n",
      "Iter  44 : loss =  tensor(4.7379)  gradnorm =  tensor(0.0973, dtype=torch.float64)\n",
      "Iter  45 : loss =  tensor(4.5567)  gradnorm =  tensor(0.0955, dtype=torch.float64)\n",
      "Iter  46 : loss =  tensor(4.3825)  gradnorm =  tensor(0.0936, dtype=torch.float64)\n",
      "Iter  47 : loss =  tensor(4.2150)  gradnorm =  tensor(0.0918, dtype=torch.float64)\n",
      "Iter  48 : loss =  tensor(4.0538)  gradnorm =  tensor(0.0900, dtype=torch.float64)\n",
      "Iter  49 : loss =  tensor(3.8988)  gradnorm =  tensor(0.0883, dtype=torch.float64)\n",
      "Iter  50 : loss =  tensor(3.7497)  gradnorm =  tensor(0.0866, dtype=torch.float64)\n",
      "Iter  51 : loss =  tensor(3.6064)  gradnorm =  tensor(0.0849, dtype=torch.float64)\n",
      "Iter  52 : loss =  tensor(3.4684)  gradnorm =  tensor(0.0833, dtype=torch.float64)\n",
      "Iter  53 : loss =  tensor(3.3358)  gradnorm =  tensor(0.0817, dtype=torch.float64)\n",
      "Iter  54 : loss =  tensor(3.2082)  gradnorm =  tensor(0.0801, dtype=torch.float64)\n",
      "Iter  55 : loss =  tensor(3.0855)  gradnorm =  tensor(0.0786, dtype=torch.float64)\n",
      "Iter  56 : loss =  tensor(2.9675)  gradnorm =  tensor(0.0770, dtype=torch.float64)\n",
      "Iter  57 : loss =  tensor(2.8540)  gradnorm =  tensor(0.0756, dtype=torch.float64)\n",
      "Iter  58 : loss =  tensor(2.7448)  gradnorm =  tensor(0.0741, dtype=torch.float64)\n",
      "Iter  59 : loss =  tensor(2.6399)  gradnorm =  tensor(0.0727, dtype=torch.float64)\n",
      "Iter  60 : loss =  tensor(2.5389)  gradnorm =  tensor(0.0713, dtype=torch.float64)\n",
      "Iter  61 : loss =  tensor(2.4418)  gradnorm =  tensor(0.0699, dtype=torch.float64)\n",
      "Iter  62 : loss =  tensor(3.3975)  gradnorm =  tensor(1.2548, dtype=torch.float64)\n",
      "Iter  63 : loss =  tensor(3.5937)  gradnorm =  tensor(1.3100, dtype=torch.float64)\n",
      "Iter  64 : loss =  tensor(2.8448)  gradnorm =  tensor(0.0754, dtype=torch.float64)\n",
      "Iter  65 : loss =  tensor(2.7360)  gradnorm =  tensor(0.0740, dtype=torch.float64)\n",
      "Iter  66 : loss =  tensor(2.6314)  gradnorm =  tensor(0.0725, dtype=torch.float64)\n",
      "Iter  67 : loss =  tensor(2.5308)  gradnorm =  tensor(0.0711, dtype=torch.float64)\n",
      "Iter  68 : loss =  tensor(2.4341)  gradnorm =  tensor(0.0698, dtype=torch.float64)\n",
      "Iter  69 : loss =  tensor(2.3410)  gradnorm =  tensor(0.0684, dtype=torch.float64)\n",
      "Iter  70 : loss =  tensor(2.2515)  gradnorm =  tensor(0.0671, dtype=torch.float64)\n",
      "Iter  71 : loss =  tensor(2.1654)  gradnorm =  tensor(0.0658, dtype=torch.float64)\n",
      "Iter  72 : loss =  tensor(4.8888)  gradnorm =  tensor(3.0996, dtype=torch.float64)\n",
      "Iter  73 : loss =  tensor(13.4045)  gradnorm =  tensor(2.7753, dtype=torch.float64)\n",
      "Iter  74 : loss =  tensor(5.5064)  gradnorm =  tensor(0.1049, dtype=torch.float64)\n",
      "Iter  75 : loss =  tensor(5.2959)  gradnorm =  tensor(0.1029, dtype=torch.float64)\n",
      "Iter  76 : loss =  tensor(5.0935)  gradnorm =  tensor(0.1009, dtype=torch.float64)\n",
      "Iter  77 : loss =  tensor(4.8988)  gradnorm =  tensor(0.0990, dtype=torch.float64)\n",
      "Iter  78 : loss =  tensor(4.7116)  gradnorm =  tensor(0.0971, dtype=torch.float64)\n",
      "Iter  79 : loss =  tensor(4.5315)  gradnorm =  tensor(0.0952, dtype=torch.float64)\n",
      "Iter  80 : loss =  tensor(4.3583)  gradnorm =  tensor(0.0934, dtype=torch.float64)\n",
      "Iter  81 : loss =  tensor(4.1917)  gradnorm =  tensor(0.0916, dtype=torch.float64)\n",
      "Iter  82 : loss =  tensor(6.3973)  gradnorm =  tensor(2.3602, dtype=torch.float64)\n",
      "Iter  83 : loss =  tensor(5.1038)  gradnorm =  tensor(0.1010, dtype=torch.float64)\n",
      "Iter  84 : loss =  tensor(4.9084)  gradnorm =  tensor(0.0991, dtype=torch.float64)\n",
      "Iter  85 : loss =  tensor(4.7206)  gradnorm =  tensor(0.0972, dtype=torch.float64)\n",
      "Iter  86 : loss =  tensor(4.5399)  gradnorm =  tensor(0.0953, dtype=torch.float64)\n",
      "Iter  87 : loss =  tensor(4.3662)  gradnorm =  tensor(0.0934, dtype=torch.float64)\n",
      "Iter  88 : loss =  tensor(4.1990)  gradnorm =  tensor(0.0916, dtype=torch.float64)\n",
      "Iter  89 : loss =  tensor(4.0383)  gradnorm =  tensor(0.0899, dtype=torch.float64)\n",
      "Iter  90 : loss =  tensor(3.8838)  gradnorm =  tensor(0.0881, dtype=torch.float64)\n",
      "Iter  91 : loss =  tensor(3.7351)  gradnorm =  tensor(0.0864, dtype=torch.float64)\n",
      "Iter  92 : loss =  tensor(4.3212)  gradnorm =  tensor(0.9179, dtype=torch.float64)\n",
      "Iter  93 : loss =  tensor(3.5715)  gradnorm =  tensor(0.0845, dtype=torch.float64)\n",
      "Iter  94 : loss =  tensor(3.4354)  gradnorm =  tensor(0.0829, dtype=torch.float64)\n",
      "Iter  95 : loss =  tensor(3.3045)  gradnorm =  tensor(0.0813, dtype=torch.float64)\n",
      "Iter  96 : loss =  tensor(3.1785)  gradnorm =  tensor(0.0797, dtype=torch.float64)\n",
      "Iter  97 : loss =  tensor(3.0574)  gradnorm =  tensor(0.0782, dtype=torch.float64)\n",
      "Iter  98 : loss =  tensor(2.9409)  gradnorm =  tensor(0.0767, dtype=torch.float64)\n",
      "Iter  99 : loss =  tensor(2.8288)  gradnorm =  tensor(0.0752, dtype=torch.float64)\n",
      "Iter  100 : loss =  tensor(2.7210)  gradnorm =  tensor(0.0738, dtype=torch.float64)\n",
      "Iter  101 : loss =  tensor(2.6173)  gradnorm =  tensor(0.0724, dtype=torch.float64)\n",
      "Iter  102 : loss =  tensor(2.5175)  gradnorm =  tensor(0.0710, dtype=torch.float64)\n",
      "Iter  103 : loss =  tensor(2.4217)  gradnorm =  tensor(0.0696, dtype=torch.float64)\n",
      "Iter  104 : loss =  tensor(2.3295)  gradnorm =  tensor(0.0683, dtype=torch.float64)\n",
      "Iter  105 : loss =  tensor(2.2409)  gradnorm =  tensor(0.0669, dtype=torch.float64)\n",
      "Iter  106 : loss =  tensor(2.1556)  gradnorm =  tensor(0.0657, dtype=torch.float64)\n",
      "Iter  107 : loss =  tensor(2.0735)  gradnorm =  tensor(0.0644, dtype=torch.float64)\n",
      "Iter  108 : loss =  tensor(1.9946)  gradnorm =  tensor(0.0632, dtype=torch.float64)\n",
      "Iter  109 : loss =  tensor(1.9187)  gradnorm =  tensor(0.0619, dtype=torch.float64)\n",
      "Iter  110 : loss =  tensor(1.8456)  gradnorm =  tensor(0.0608, dtype=torch.float64)\n",
      "Iter  111 : loss =  tensor(1.7754)  gradnorm =  tensor(0.0596, dtype=torch.float64)\n",
      "Iter  112 : loss =  tensor(1.7078)  gradnorm =  tensor(0.0584, dtype=torch.float64)\n",
      "Iter  113 : loss =  tensor(1.6429)  gradnorm =  tensor(0.0573, dtype=torch.float64)\n",
      "Iter  114 : loss =  tensor(1.5805)  gradnorm =  tensor(0.0562, dtype=torch.float64)\n",
      "Iter  115 : loss =  tensor(1.5205)  gradnorm =  tensor(0.0551, dtype=torch.float64)\n",
      "Iter  116 : loss =  tensor(1.4627)  gradnorm =  tensor(0.0541, dtype=torch.float64)\n",
      "Iter  117 : loss =  tensor(1.4071)  gradnorm =  tensor(0.0530, dtype=torch.float64)\n",
      "Iter  118 : loss =  tensor(1.3537)  gradnorm =  tensor(0.0520, dtype=torch.float64)\n",
      "Iter  119 : loss =  tensor(1.3023)  gradnorm =  tensor(0.0510, dtype=torch.float64)\n",
      "Iter  120 : loss =  tensor(1.2528)  gradnorm =  tensor(0.0501, dtype=torch.float64)\n",
      "Iter  121 : loss =  tensor(1.2052)  gradnorm =  tensor(0.0491, dtype=torch.float64)\n",
      "Iter  122 : loss =  tensor(1.1594)  gradnorm =  tensor(0.0482, dtype=torch.float64)\n",
      "Iter  123 : loss =  tensor(1.1155)  gradnorm =  tensor(0.0472, dtype=torch.float64)\n",
      "Iter  124 : loss =  tensor(1.0733)  gradnorm =  tensor(0.0463, dtype=torch.float64)\n",
      "Iter  125 : loss =  tensor(1.0326)  gradnorm =  tensor(0.0454, dtype=torch.float64)\n",
      "Iter  126 : loss =  tensor(0.9935)  gradnorm =  tensor(0.0446, dtype=torch.float64)\n",
      "Iter  127 : loss =  tensor(0.9559)  gradnorm =  tensor(0.0437, dtype=torch.float64)\n",
      "Iter  128 : loss =  tensor(0.9197)  gradnorm =  tensor(0.0429, dtype=torch.float64)\n",
      "Iter  129 : loss =  tensor(0.8849)  gradnorm =  tensor(0.0421, dtype=torch.float64)\n",
      "Iter  130 : loss =  tensor(0.8514)  gradnorm =  tensor(0.0413, dtype=torch.float64)\n",
      "Iter  131 : loss =  tensor(0.8192)  gradnorm =  tensor(0.0405, dtype=torch.float64)\n",
      "Iter  132 : loss =  tensor(4.9049)  gradnorm =  tensor(1.4599, dtype=torch.float64)\n",
      "Iter  133 : loss =  tensor(1.6384)  gradnorm =  tensor(0.9553, dtype=torch.float64)\n",
      "Iter  134 : loss =  tensor(1.3019)  gradnorm =  tensor(0.0510, dtype=torch.float64)\n",
      "Iter  135 : loss =  tensor(1.2526)  gradnorm =  tensor(0.0501, dtype=torch.float64)\n",
      "Iter  136 : loss =  tensor(1.2051)  gradnorm =  tensor(0.0491, dtype=torch.float64)\n",
      "Iter  137 : loss =  tensor(1.1595)  gradnorm =  tensor(0.0482, dtype=torch.float64)\n",
      "Iter  138 : loss =  tensor(1.1156)  gradnorm =  tensor(0.0472, dtype=torch.float64)\n",
      "Iter  139 : loss =  tensor(1.0734)  gradnorm =  tensor(0.0463, dtype=torch.float64)\n",
      "Iter  140 : loss =  tensor(1.0327)  gradnorm =  tensor(0.0454, dtype=torch.float64)\n",
      "Iter  141 : loss =  tensor(0.9936)  gradnorm =  tensor(0.0446, dtype=torch.float64)\n",
      "Iter  142 : loss =  tensor(0.9560)  gradnorm =  tensor(0.0437, dtype=torch.float64)\n",
      "Iter  143 : loss =  tensor(0.9198)  gradnorm =  tensor(0.0429, dtype=torch.float64)\n",
      "Iter  144 : loss =  tensor(0.8849)  gradnorm =  tensor(0.0421, dtype=torch.float64)\n",
      "Iter  145 : loss =  tensor(0.8514)  gradnorm =  tensor(0.0413, dtype=torch.float64)\n",
      "Iter  146 : loss =  tensor(0.8191)  gradnorm =  tensor(0.0405, dtype=torch.float64)\n",
      "Iter  147 : loss =  tensor(0.7881)  gradnorm =  tensor(0.0397, dtype=torch.float64)\n",
      "Iter  148 : loss =  tensor(0.7582)  gradnorm =  tensor(0.0389, dtype=torch.float64)\n",
      "Iter  149 : loss =  tensor(0.7295)  gradnorm =  tensor(0.0382, dtype=torch.float64)\n",
      "Iter  150 : loss =  tensor(0.7018)  gradnorm =  tensor(0.0375, dtype=torch.float64)\n",
      "Iter  151 : loss =  tensor(0.6752)  gradnorm =  tensor(0.0367, dtype=torch.float64)\n",
      "Iter  152 : loss =  tensor(0.6496)  gradnorm =  tensor(0.0360, dtype=torch.float64)\n",
      "Iter  153 : loss =  tensor(0.6251)  gradnorm =  tensor(0.0354, dtype=torch.float64)\n",
      "Iter  154 : loss =  tensor(0.6015)  gradnorm =  tensor(0.0347, dtype=torch.float64)\n",
      "Iter  155 : loss =  tensor(0.5788)  gradnorm =  tensor(0.0340, dtype=torch.float64)\n",
      "Iter  156 : loss =  tensor(0.5570)  gradnorm =  tensor(0.0334, dtype=torch.float64)\n",
      "Iter  157 : loss =  tensor(0.5360)  gradnorm =  tensor(0.0327, dtype=torch.float64)\n",
      "Iter  158 : loss =  tensor(0.5158)  gradnorm =  tensor(0.0321, dtype=torch.float64)\n",
      "Iter  159 : loss =  tensor(0.4963)  gradnorm =  tensor(0.0315, dtype=torch.float64)\n",
      "Iter  160 : loss =  tensor(0.4776)  gradnorm =  tensor(0.0309, dtype=torch.float64)\n",
      "Iter  161 : loss =  tensor(0.4596)  gradnorm =  tensor(0.0303, dtype=torch.float64)\n",
      "Iter  162 : loss =  tensor(1.1179)  gradnorm =  tensor(2.0006, dtype=torch.float64)\n",
      "Iter  163 : loss =  tensor(19.1543)  gradnorm =  tensor(4.4975, dtype=torch.float64)\n",
      "Iter  164 : loss =  tensor(49.1224)  gradnorm =  tensor(3.5519, dtype=torch.float64)\n",
      "Iter  165 : loss =  tensor(15.6404)  gradnorm =  tensor(0.9785, dtype=torch.float64)\n",
      "Iter  166 : loss =  tensor(16.7307)  gradnorm =  tensor(3.4258, dtype=torch.float64)\n",
      "Iter  167 : loss =  tensor(9.1440)  gradnorm =  tensor(0.1352, dtype=torch.float64)\n",
      "Iter  168 : loss =  tensor(8.7944)  gradnorm =  tensor(0.1326, dtype=torch.float64)\n",
      "Iter  169 : loss =  tensor(8.4581)  gradnorm =  tensor(0.1301, dtype=torch.float64)\n",
      "Iter  170 : loss =  tensor(8.1347)  gradnorm =  tensor(0.1276, dtype=torch.float64)\n",
      "Iter  171 : loss =  tensor(7.8237)  gradnorm =  tensor(0.1251, dtype=torch.float64)\n",
      "Iter  172 : loss =  tensor(26.2434)  gradnorm =  tensor(2.3547, dtype=torch.float64)\n",
      "Iter  173 : loss =  tensor(13.9630)  gradnorm =  tensor(2.5416, dtype=torch.float64)\n",
      "Iter  174 : loss =  tensor(9.0936)  gradnorm =  tensor(0.1349, dtype=torch.float64)\n",
      "Iter  175 : loss =  tensor(8.7460)  gradnorm =  tensor(0.1323, dtype=torch.float64)\n",
      "Iter  176 : loss =  tensor(8.4117)  gradnorm =  tensor(0.1297, dtype=torch.float64)\n",
      "Iter  177 : loss =  tensor(8.0902)  gradnorm =  tensor(0.1272, dtype=torch.float64)\n",
      "Iter  178 : loss =  tensor(7.7810)  gradnorm =  tensor(0.1247, dtype=torch.float64)\n",
      "Iter  179 : loss =  tensor(7.4835)  gradnorm =  tensor(0.1223, dtype=torch.float64)\n",
      "Iter  180 : loss =  tensor(7.1975)  gradnorm =  tensor(0.1200, dtype=torch.float64)\n",
      "Iter  181 : loss =  tensor(6.9224)  gradnorm =  tensor(0.1177, dtype=torch.float64)\n",
      "Iter  182 : loss =  tensor(18.7895)  gradnorm =  tensor(2.1005, dtype=torch.float64)\n",
      "Iter  183 : loss =  tensor(7.0482)  gradnorm =  tensor(0.1187, dtype=torch.float64)\n",
      "Iter  184 : loss =  tensor(6.7799)  gradnorm =  tensor(0.1164, dtype=torch.float64)\n",
      "Iter  185 : loss =  tensor(6.5218)  gradnorm =  tensor(0.1142, dtype=torch.float64)\n",
      "Iter  186 : loss =  tensor(6.2736)  gradnorm =  tensor(0.1120, dtype=torch.float64)\n",
      "Iter  187 : loss =  tensor(6.0348)  gradnorm =  tensor(0.1099, dtype=torch.float64)\n",
      "Iter  188 : loss =  tensor(5.8051)  gradnorm =  tensor(0.1078, dtype=torch.float64)\n",
      "Iter  189 : loss =  tensor(5.5842)  gradnorm =  tensor(0.1057, dtype=torch.float64)\n",
      "Iter  190 : loss =  tensor(5.3716)  gradnorm =  tensor(0.1036, dtype=torch.float64)\n",
      "Iter  191 : loss =  tensor(5.1672)  gradnorm =  tensor(0.1017, dtype=torch.float64)\n",
      "Iter  192 : loss =  tensor(4.9706)  gradnorm =  tensor(0.0997, dtype=torch.float64)\n",
      "Iter  193 : loss =  tensor(4.7816)  gradnorm =  tensor(0.0978, dtype=torch.float64)\n",
      "Iter  194 : loss =  tensor(4.5999)  gradnorm =  tensor(0.0959, dtype=torch.float64)\n",
      "Iter  195 : loss =  tensor(4.4251)  gradnorm =  tensor(0.0941, dtype=torch.float64)\n",
      "Iter  196 : loss =  tensor(4.2570)  gradnorm =  tensor(0.0923, dtype=torch.float64)\n",
      "Iter  197 : loss =  tensor(4.0952)  gradnorm =  tensor(0.0905, dtype=torch.float64)\n",
      "Iter  198 : loss =  tensor(3.9396)  gradnorm =  tensor(0.0888, dtype=torch.float64)\n",
      "Iter  199 : loss =  tensor(3.7899)  gradnorm =  tensor(0.0871, dtype=torch.float64)\n",
      "Iter  200 : loss =  tensor(3.6459)  gradnorm =  tensor(0.0854, dtype=torch.float64)\n",
      "Iter  201 : loss =  tensor(3.5074)  gradnorm =  tensor(0.0838, dtype=torch.float64)\n",
      "Iter  202 : loss =  tensor(4.7486)  gradnorm =  tensor(0.7831, dtype=torch.float64)\n",
      "Iter  203 : loss =  tensor(3.3538)  gradnorm =  tensor(0.0819, dtype=torch.float64)\n",
      "Iter  204 : loss =  tensor(3.2265)  gradnorm =  tensor(0.0803, dtype=torch.float64)\n",
      "Iter  205 : loss =  tensor(3.1039)  gradnorm =  tensor(0.0788, dtype=torch.float64)\n",
      "Iter  206 : loss =  tensor(2.9860)  gradnorm =  tensor(0.0773, dtype=torch.float64)\n",
      "Iter  207 : loss =  tensor(2.8727)  gradnorm =  tensor(0.0758, dtype=torch.float64)\n",
      "Iter  208 : loss =  tensor(2.7636)  gradnorm =  tensor(0.0743, dtype=torch.float64)\n",
      "Iter  209 : loss =  tensor(2.6586)  gradnorm =  tensor(0.0729, dtype=torch.float64)\n",
      "Iter  210 : loss =  tensor(2.5577)  gradnorm =  tensor(0.0715, dtype=torch.float64)\n",
      "Iter  211 : loss =  tensor(2.4606)  gradnorm =  tensor(0.0702, dtype=torch.float64)\n",
      "Iter  212 : loss =  tensor(2.3671)  gradnorm =  tensor(0.0688, dtype=torch.float64)\n",
      "Iter  213 : loss =  tensor(2.2775)  gradnorm =  tensor(0.0675, dtype=torch.float64)\n",
      "Iter  214 : loss =  tensor(2.1913)  gradnorm =  tensor(0.0662, dtype=torch.float64)\n",
      "Iter  215 : loss =  tensor(2.1083)  gradnorm =  tensor(0.0649, dtype=torch.float64)\n",
      "Iter  216 : loss =  tensor(2.0285)  gradnorm =  tensor(0.0637, dtype=torch.float64)\n",
      "Iter  217 : loss =  tensor(1.9518)  gradnorm =  tensor(0.0625, dtype=torch.float64)\n",
      "Iter  218 : loss =  tensor(1.8779)  gradnorm =  tensor(0.0613, dtype=torch.float64)\n",
      "Iter  219 : loss =  tensor(1.8068)  gradnorm =  tensor(0.0601, dtype=torch.float64)\n",
      "Iter  220 : loss =  tensor(1.7385)  gradnorm =  tensor(0.0590, dtype=torch.float64)\n",
      "Iter  221 : loss =  tensor(1.6727)  gradnorm =  tensor(0.0578, dtype=torch.float64)\n",
      "Iter  222 : loss =  tensor(1.6094)  gradnorm =  tensor(0.0567, dtype=torch.float64)\n",
      "Iter  223 : loss =  tensor(1.5488)  gradnorm =  tensor(0.0557, dtype=torch.float64)\n",
      "Iter  224 : loss =  tensor(1.4905)  gradnorm =  tensor(0.0546, dtype=torch.float64)\n",
      "Iter  225 : loss =  tensor(1.4344)  gradnorm =  tensor(0.0536, dtype=torch.float64)\n",
      "Iter  226 : loss =  tensor(1.3804)  gradnorm =  tensor(0.0525, dtype=torch.float64)\n",
      "Iter  227 : loss =  tensor(1.3285)  gradnorm =  tensor(0.0515, dtype=torch.float64)\n",
      "Iter  228 : loss =  tensor(1.2785)  gradnorm =  tensor(0.0506, dtype=torch.float64)\n",
      "Iter  229 : loss =  tensor(1.2304)  gradnorm =  tensor(0.0496, dtype=torch.float64)\n",
      "Iter  230 : loss =  tensor(1.1842)  gradnorm =  tensor(0.0487, dtype=torch.float64)\n",
      "Iter  231 : loss =  tensor(1.1397)  gradnorm =  tensor(0.0477, dtype=torch.float64)\n",
      "Iter  232 : loss =  tensor(1.0968)  gradnorm =  tensor(0.0468, dtype=torch.float64)\n",
      "Iter  233 : loss =  tensor(1.0559)  gradnorm =  tensor(0.0460, dtype=torch.float64)\n",
      "Iter  234 : loss =  tensor(1.0166)  gradnorm =  tensor(0.0451, dtype=torch.float64)\n",
      "Iter  235 : loss =  tensor(0.9787)  gradnorm =  tensor(0.0442, dtype=torch.float64)\n",
      "Iter  236 : loss =  tensor(0.9423)  gradnorm =  tensor(0.0434, dtype=torch.float64)\n",
      "Iter  237 : loss =  tensor(0.9072)  gradnorm =  tensor(0.0426, dtype=torch.float64)\n",
      "Iter  238 : loss =  tensor(0.8735)  gradnorm =  tensor(0.0418, dtype=torch.float64)\n",
      "Iter  239 : loss =  tensor(0.8410)  gradnorm =  tensor(0.0410, dtype=torch.float64)\n",
      "Iter  240 : loss =  tensor(0.8098)  gradnorm =  tensor(0.0402, dtype=torch.float64)\n",
      "Iter  241 : loss =  tensor(0.7797)  gradnorm =  tensor(0.0395, dtype=torch.float64)\n",
      "Iter  242 : loss =  tensor(2.0698)  gradnorm =  tensor(0.7795, dtype=torch.float64)\n",
      "Iter  243 : loss =  tensor(3.7271)  gradnorm =  tensor(2.6004, dtype=torch.float64)\n",
      "Iter  244 : loss =  tensor(7.4491)  gradnorm =  tensor(2.0079, dtype=torch.float64)\n",
      "Iter  245 : loss =  tensor(46.4174)  gradnorm =  tensor(5.6125, dtype=torch.float64)\n",
      "Iter  246 : loss =  tensor(107.9321)  gradnorm =  tensor(6.7092, dtype=torch.float64)\n",
      "Iter  247 : loss =  tensor(16.6261)  gradnorm =  tensor(0.1824, dtype=torch.float64)\n",
      "Iter  248 : loss =  tensor(15.9877)  gradnorm =  tensor(0.1788, dtype=torch.float64)\n",
      "Iter  249 : loss =  tensor(15.3738)  gradnorm =  tensor(0.1753, dtype=torch.float64)\n",
      "Iter  250 : loss =  tensor(14.7835)  gradnorm =  tensor(0.1720, dtype=torch.float64)\n",
      "Iter  251 : loss =  tensor(14.2158)  gradnorm =  tensor(0.1686, dtype=torch.float64)\n",
      "Iter  252 : loss =  tensor(61.9449)  gradnorm =  tensor(5.2342, dtype=torch.float64)\n",
      "Iter  253 : loss =  tensor(64.7625)  gradnorm =  tensor(2.3470, dtype=torch.float64)\n",
      "Iter  254 : loss =  tensor(17.8210)  gradnorm =  tensor(0.1888, dtype=torch.float64)\n",
      "Iter  255 : loss =  tensor(17.1400)  gradnorm =  tensor(0.1851, dtype=torch.float64)\n",
      "Iter  256 : loss =  tensor(16.4850)  gradnorm =  tensor(0.1816, dtype=torch.float64)\n",
      "Iter  257 : loss =  tensor(15.8550)  gradnorm =  tensor(0.1781, dtype=torch.float64)\n",
      "Iter  258 : loss =  tensor(15.2491)  gradnorm =  tensor(0.1746, dtype=torch.float64)\n",
      "Iter  259 : loss =  tensor(14.6663)  gradnorm =  tensor(0.1713, dtype=torch.float64)\n",
      "Iter  260 : loss =  tensor(14.1059)  gradnorm =  tensor(0.1680, dtype=torch.float64)\n",
      "Iter  261 : loss =  tensor(13.5668)  gradnorm =  tensor(0.1647, dtype=torch.float64)\n",
      "Iter  262 : loss =  tensor(13.0484)  gradnorm =  tensor(0.1615, dtype=torch.float64)\n",
      "Iter  263 : loss =  tensor(12.5497)  gradnorm =  tensor(0.1584, dtype=torch.float64)\n",
      "Iter  264 : loss =  tensor(12.0701)  gradnorm =  tensor(0.1554, dtype=torch.float64)\n",
      "Iter  265 : loss =  tensor(11.6088)  gradnorm =  tensor(0.1524, dtype=torch.float64)\n",
      "Iter  266 : loss =  tensor(11.1652)  gradnorm =  tensor(0.1494, dtype=torch.float64)\n",
      "Iter  267 : loss =  tensor(10.7385)  gradnorm =  tensor(0.1466, dtype=torch.float64)\n",
      "Iter  268 : loss =  tensor(10.3282)  gradnorm =  tensor(0.1437, dtype=torch.float64)\n",
      "Iter  269 : loss =  tensor(9.9335)  gradnorm =  tensor(0.1410, dtype=torch.float64)\n",
      "Iter  270 : loss =  tensor(9.5538)  gradnorm =  tensor(0.1382, dtype=torch.float64)\n",
      "Iter  271 : loss =  tensor(9.1887)  gradnorm =  tensor(0.1356, dtype=torch.float64)\n",
      "Iter  272 : loss =  tensor(8.8376)  gradnorm =  tensor(0.1329, dtype=torch.float64)\n",
      "Iter  273 : loss =  tensor(8.4998)  gradnorm =  tensor(0.1304, dtype=torch.float64)\n",
      "Iter  274 : loss =  tensor(8.1750)  gradnorm =  tensor(0.1279, dtype=torch.float64)\n",
      "Iter  275 : loss =  tensor(7.8626)  gradnorm =  tensor(0.1254, dtype=torch.float64)\n",
      "Iter  276 : loss =  tensor(7.5621)  gradnorm =  tensor(0.1230, dtype=torch.float64)\n",
      "Iter  277 : loss =  tensor(7.2731)  gradnorm =  tensor(0.1206, dtype=torch.float64)\n",
      "Iter  278 : loss =  tensor(6.9951)  gradnorm =  tensor(0.1183, dtype=torch.float64)\n",
      "Iter  279 : loss =  tensor(6.7278)  gradnorm =  tensor(0.1160, dtype=torch.float64)\n",
      "Iter  280 : loss =  tensor(6.4707)  gradnorm =  tensor(0.1138, dtype=torch.float64)\n",
      "Iter  281 : loss =  tensor(6.2234)  gradnorm =  tensor(0.1116, dtype=torch.float64)\n",
      "Iter  282 : loss =  tensor(6.0828)  gradnorm =  tensor(1.1897, dtype=torch.float64)\n",
      "Iter  283 : loss =  tensor(6.0492)  gradnorm =  tensor(0.1100, dtype=torch.float64)\n",
      "Iter  284 : loss =  tensor(5.8181)  gradnorm =  tensor(0.1079, dtype=torch.float64)\n",
      "Iter  285 : loss =  tensor(5.5957)  gradnorm =  tensor(0.1058, dtype=torch.float64)\n",
      "Iter  286 : loss =  tensor(5.3819)  gradnorm =  tensor(0.1037, dtype=torch.float64)\n",
      "Iter  287 : loss =  tensor(5.1763)  gradnorm =  tensor(0.1017, dtype=torch.float64)\n",
      "Iter  288 : loss =  tensor(4.9785)  gradnorm =  tensor(0.0998, dtype=torch.float64)\n",
      "Iter  289 : loss =  tensor(4.7882)  gradnorm =  tensor(0.0979, dtype=torch.float64)\n",
      "Iter  290 : loss =  tensor(4.6053)  gradnorm =  tensor(0.0960, dtype=torch.float64)\n",
      "Iter  291 : loss =  tensor(4.4293)  gradnorm =  tensor(0.0941, dtype=torch.float64)\n",
      "Iter  292 : loss =  tensor(6.7746)  gradnorm =  tensor(0.8919, dtype=torch.float64)\n",
      "Iter  293 : loss =  tensor(4.5878)  gradnorm =  tensor(0.8109, dtype=torch.float64)\n",
      "Iter  294 : loss =  tensor(4.1688)  gradnorm =  tensor(0.0913, dtype=torch.float64)\n",
      "Iter  295 : loss =  tensor(4.0095)  gradnorm =  tensor(0.0895, dtype=torch.float64)\n",
      "Iter  296 : loss =  tensor(3.8563)  gradnorm =  tensor(0.0878, dtype=torch.float64)\n",
      "Iter  297 : loss =  tensor(3.7089)  gradnorm =  tensor(0.0861, dtype=torch.float64)\n",
      "Iter  298 : loss =  tensor(3.5672)  gradnorm =  tensor(0.0845, dtype=torch.float64)\n",
      "Iter  299 : loss =  tensor(3.4309)  gradnorm =  tensor(0.0828, dtype=torch.float64)\n",
      "Iter  300 : loss =  tensor(3.2998)  gradnorm =  tensor(0.0812, dtype=torch.float64)\n",
      "Iter  301 : loss =  tensor(3.1737)  gradnorm =  tensor(0.0797, dtype=torch.float64)\n",
      "Iter  302 : loss =  tensor(12.8458)  gradnorm =  tensor(0.9368, dtype=torch.float64)\n",
      "Iter  303 : loss =  tensor(2.9188)  gradnorm =  tensor(0.0764, dtype=torch.float64)\n",
      "Iter  304 : loss =  tensor(2.8071)  gradnorm =  tensor(0.0749, dtype=torch.float64)\n",
      "Iter  305 : loss =  tensor(2.6998)  gradnorm =  tensor(0.0735, dtype=torch.float64)\n",
      "Iter  306 : loss =  tensor(2.5965)  gradnorm =  tensor(0.0721, dtype=torch.float64)\n",
      "Iter  307 : loss =  tensor(2.4972)  gradnorm =  tensor(0.0707, dtype=torch.float64)\n",
      "Iter  308 : loss =  tensor(2.4017)  gradnorm =  tensor(0.0693, dtype=torch.float64)\n",
      "Iter  309 : loss =  tensor(2.3098)  gradnorm =  tensor(0.0680, dtype=torch.float64)\n",
      "Iter  310 : loss =  tensor(2.2215)  gradnorm =  tensor(0.0667, dtype=torch.float64)\n",
      "Iter  311 : loss =  tensor(2.1365)  gradnorm =  tensor(0.0654, dtype=torch.float64)\n",
      "Iter  312 : loss =  tensor(2.3830)  gradnorm =  tensor(1.5532, dtype=torch.float64)\n",
      "Iter  313 : loss =  tensor(2.5180)  gradnorm =  tensor(0.0710, dtype=torch.float64)\n",
      "Iter  314 : loss =  tensor(2.4216)  gradnorm =  tensor(0.0696, dtype=torch.float64)\n",
      "Iter  315 : loss =  tensor(2.3290)  gradnorm =  tensor(0.0682, dtype=torch.float64)\n",
      "Iter  316 : loss =  tensor(2.2398)  gradnorm =  tensor(0.0669, dtype=torch.float64)\n",
      "Iter  317 : loss =  tensor(2.1541)  gradnorm =  tensor(0.0656, dtype=torch.float64)\n",
      "Iter  318 : loss =  tensor(2.0717)  gradnorm =  tensor(0.0644, dtype=torch.float64)\n",
      "Iter  319 : loss =  tensor(1.9924)  gradnorm =  tensor(0.0631, dtype=torch.float64)\n",
      "Iter  320 : loss =  tensor(1.9161)  gradnorm =  tensor(0.0619, dtype=torch.float64)\n",
      "Iter  321 : loss =  tensor(1.8428)  gradnorm =  tensor(0.0607, dtype=torch.float64)\n",
      "Iter  322 : loss =  tensor(4.2672)  gradnorm =  tensor(1.1371, dtype=torch.float64)\n",
      "Iter  323 : loss =  tensor(1.9021)  gradnorm =  tensor(0.0617, dtype=torch.float64)\n",
      "Iter  324 : loss =  tensor(1.8296)  gradnorm =  tensor(0.0605, dtype=torch.float64)\n",
      "Iter  325 : loss =  tensor(1.7598)  gradnorm =  tensor(0.0593, dtype=torch.float64)\n",
      "Iter  326 : loss =  tensor(1.6927)  gradnorm =  tensor(0.0582, dtype=torch.float64)\n",
      "Iter  327 : loss =  tensor(1.6281)  gradnorm =  tensor(0.0571, dtype=torch.float64)\n",
      "Iter  328 : loss =  tensor(1.5660)  gradnorm =  tensor(0.0560, dtype=torch.float64)\n",
      "Iter  329 : loss =  tensor(1.5063)  gradnorm =  tensor(0.0549, dtype=torch.float64)\n",
      "Iter  330 : loss =  tensor(1.4488)  gradnorm =  tensor(0.0538, dtype=torch.float64)\n",
      "Iter  331 : loss =  tensor(1.3936)  gradnorm =  tensor(0.0528, dtype=torch.float64)\n",
      "Iter  332 : loss =  tensor(1.3404)  gradnorm =  tensor(0.0518, dtype=torch.float64)\n",
      "Iter  333 : loss =  tensor(1.2893)  gradnorm =  tensor(0.0508, dtype=torch.float64)\n",
      "Iter  334 : loss =  tensor(1.2402)  gradnorm =  tensor(0.0498, dtype=torch.float64)\n",
      "Iter  335 : loss =  tensor(1.1929)  gradnorm =  tensor(0.0488, dtype=torch.float64)\n",
      "Iter  336 : loss =  tensor(1.1474)  gradnorm =  tensor(0.0479, dtype=torch.float64)\n",
      "Iter  337 : loss =  tensor(1.1037)  gradnorm =  tensor(0.0470, dtype=torch.float64)\n",
      "Iter  338 : loss =  tensor(1.0616)  gradnorm =  tensor(0.0461, dtype=torch.float64)\n",
      "Iter  339 : loss =  tensor(1.0211)  gradnorm =  tensor(0.0452, dtype=torch.float64)\n",
      "Iter  340 : loss =  tensor(0.9822)  gradnorm =  tensor(0.0443, dtype=torch.float64)\n",
      "Iter  341 : loss =  tensor(0.9448)  gradnorm =  tensor(0.0435, dtype=torch.float64)\n",
      "Iter  342 : loss =  tensor(0.9088)  gradnorm =  tensor(0.0426, dtype=torch.float64)\n",
      "Iter  343 : loss =  tensor(0.8742)  gradnorm =  tensor(0.0418, dtype=torch.float64)\n",
      "Iter  344 : loss =  tensor(0.8409)  gradnorm =  tensor(0.0410, dtype=torch.float64)\n",
      "Iter  345 : loss =  tensor(0.8089)  gradnorm =  tensor(0.0402, dtype=torch.float64)\n",
      "Iter  346 : loss =  tensor(0.7781)  gradnorm =  tensor(0.0394, dtype=torch.float64)\n",
      "Iter  347 : loss =  tensor(0.7485)  gradnorm =  tensor(0.0387, dtype=torch.float64)\n",
      "Iter  348 : loss =  tensor(0.7200)  gradnorm =  tensor(0.0379, dtype=torch.float64)\n",
      "Iter  349 : loss =  tensor(0.6926)  gradnorm =  tensor(0.0372, dtype=torch.float64)\n",
      "Iter  350 : loss =  tensor(0.6662)  gradnorm =  tensor(0.0365, dtype=torch.float64)\n",
      "Iter  351 : loss =  tensor(0.6408)  gradnorm =  tensor(0.0358, dtype=torch.float64)\n",
      "Iter  352 : loss =  tensor(2.5641)  gradnorm =  tensor(1.4451, dtype=torch.float64)\n",
      "Iter  353 : loss =  tensor(13.9643)  gradnorm =  tensor(3.5824, dtype=torch.float64)\n",
      "Iter  354 : loss =  tensor(47.1923)  gradnorm =  tensor(7.0493, dtype=torch.float64)\n",
      "Iter  355 : loss =  tensor(31.8417)  gradnorm =  tensor(2.6930, dtype=torch.float64)\n",
      "Iter  356 : loss =  tensor(15.2618)  gradnorm =  tensor(0.9128, dtype=torch.float64)\n",
      "Iter  357 : loss =  tensor(13.5993)  gradnorm =  tensor(0.1649, dtype=torch.float64)\n",
      "Iter  358 : loss =  tensor(13.0800)  gradnorm =  tensor(0.1617, dtype=torch.float64)\n",
      "Iter  359 : loss =  tensor(12.5806)  gradnorm =  tensor(0.1586, dtype=torch.float64)\n",
      "Iter  360 : loss =  tensor(12.1002)  gradnorm =  tensor(0.1556, dtype=torch.float64)\n",
      "Iter  361 : loss =  tensor(11.6382)  gradnorm =  tensor(0.1526, dtype=torch.float64)\n",
      "Iter  362 : loss =  tensor(33.3296)  gradnorm =  tensor(2.1008, dtype=torch.float64)\n",
      "Iter  363 : loss =  tensor(11.2588)  gradnorm =  tensor(0.1501, dtype=torch.float64)\n",
      "Iter  364 : loss =  tensor(10.8285)  gradnorm =  tensor(0.1472, dtype=torch.float64)\n",
      "Iter  365 : loss =  tensor(10.4145)  gradnorm =  tensor(0.1443, dtype=torch.float64)\n",
      "Iter  366 : loss =  tensor(10.0164)  gradnorm =  tensor(0.1415, dtype=torch.float64)\n",
      "Iter  367 : loss =  tensor(9.6335)  gradnorm =  tensor(0.1388, dtype=torch.float64)\n",
      "Iter  368 : loss =  tensor(9.2653)  gradnorm =  tensor(0.1361, dtype=torch.float64)\n",
      "Iter  369 : loss =  tensor(8.9111)  gradnorm =  tensor(0.1335, dtype=torch.float64)\n",
      "Iter  370 : loss =  tensor(8.5705)  gradnorm =  tensor(0.1309, dtype=torch.float64)\n",
      "Iter  371 : loss =  tensor(8.2429)  gradnorm =  tensor(0.1284, dtype=torch.float64)\n",
      "Iter  372 : loss =  tensor(12.8970)  gradnorm =  tensor(1.0703, dtype=torch.float64)\n",
      "Iter  373 : loss =  tensor(9.7954)  gradnorm =  tensor(1.4518, dtype=torch.float64)\n",
      "Iter  374 : loss =  tensor(7.8536)  gradnorm =  tensor(0.1253, dtype=torch.float64)\n",
      "Iter  375 : loss =  tensor(7.5533)  gradnorm =  tensor(0.1229, dtype=torch.float64)\n",
      "Iter  376 : loss =  tensor(7.2644)  gradnorm =  tensor(0.1205, dtype=torch.float64)\n",
      "Iter  377 : loss =  tensor(6.9866)  gradnorm =  tensor(0.1182, dtype=torch.float64)\n",
      "Iter  378 : loss =  tensor(6.7195)  gradnorm =  tensor(0.1159, dtype=torch.float64)\n",
      "Iter  379 : loss =  tensor(6.4625)  gradnorm =  tensor(0.1137, dtype=torch.float64)\n",
      "Iter  380 : loss =  tensor(6.2154)  gradnorm =  tensor(0.1115, dtype=torch.float64)\n",
      "Iter  381 : loss =  tensor(5.9777)  gradnorm =  tensor(0.1093, dtype=torch.float64)\n",
      "Iter  382 : loss =  tensor(5.7492)  gradnorm =  tensor(0.1072, dtype=torch.float64)\n",
      "Iter  383 : loss =  tensor(5.5292)  gradnorm =  tensor(0.1052, dtype=torch.float64)\n",
      "Iter  384 : loss =  tensor(5.3177)  gradnorm =  tensor(0.1031, dtype=torch.float64)\n",
      "Iter  385 : loss =  tensor(5.1143)  gradnorm =  tensor(0.1011, dtype=torch.float64)\n",
      "Iter  386 : loss =  tensor(4.9187)  gradnorm =  tensor(0.0992, dtype=torch.float64)\n",
      "Iter  387 : loss =  tensor(4.7306)  gradnorm =  tensor(0.0973, dtype=torch.float64)\n",
      "Iter  388 : loss =  tensor(4.5496)  gradnorm =  tensor(0.0954, dtype=torch.float64)\n",
      "Iter  389 : loss =  tensor(4.3756)  gradnorm =  tensor(0.0935, dtype=torch.float64)\n",
      "Iter  390 : loss =  tensor(4.2082)  gradnorm =  tensor(0.0917, dtype=torch.float64)\n",
      "Iter  391 : loss =  tensor(4.0473)  gradnorm =  tensor(0.0900, dtype=torch.float64)\n",
      "Iter  392 : loss =  tensor(3.8925)  gradnorm =  tensor(0.0882, dtype=torch.float64)\n",
      "Iter  393 : loss =  tensor(3.7435)  gradnorm =  tensor(0.0865, dtype=torch.float64)\n",
      "Iter  394 : loss =  tensor(3.6002)  gradnorm =  tensor(0.0849, dtype=torch.float64)\n",
      "Iter  395 : loss =  tensor(3.4625)  gradnorm =  tensor(0.0832, dtype=torch.float64)\n",
      "Iter  396 : loss =  tensor(3.3300)  gradnorm =  tensor(0.0816, dtype=torch.float64)\n",
      "Iter  397 : loss =  tensor(3.2025)  gradnorm =  tensor(0.0800, dtype=torch.float64)\n",
      "Iter  398 : loss =  tensor(3.0800)  gradnorm =  tensor(0.0785, dtype=torch.float64)\n",
      "Iter  399 : loss =  tensor(2.9621)  gradnorm =  tensor(0.0770, dtype=torch.float64)\n",
      "Iter  400 : loss =  tensor(2.8487)  gradnorm =  tensor(0.0755, dtype=torch.float64)\n",
      "Iter  401 : loss =  tensor(2.7397)  gradnorm =  tensor(0.0740, dtype=torch.float64)\n",
      "Iter  402 : loss =  tensor(2.6349)  gradnorm =  tensor(0.0726, dtype=torch.float64)\n",
      "Iter  403 : loss =  tensor(2.5340)  gradnorm =  tensor(0.0712, dtype=torch.float64)\n",
      "Iter  404 : loss =  tensor(2.4369)  gradnorm =  tensor(0.0698, dtype=torch.float64)\n",
      "Iter  405 : loss =  tensor(2.3436)  gradnorm =  tensor(0.0685, dtype=torch.float64)\n",
      "Iter  406 : loss =  tensor(2.2539)  gradnorm =  tensor(0.0671, dtype=torch.float64)\n",
      "Iter  407 : loss =  tensor(2.1675)  gradnorm =  tensor(0.0658, dtype=torch.float64)\n",
      "Iter  408 : loss =  tensor(2.0845)  gradnorm =  tensor(0.0646, dtype=torch.float64)\n",
      "Iter  409 : loss =  tensor(2.0047)  gradnorm =  tensor(0.0633, dtype=torch.float64)\n",
      "Iter  410 : loss =  tensor(1.9279)  gradnorm =  tensor(0.0621, dtype=torch.float64)\n",
      "Iter  411 : loss =  tensor(1.8541)  gradnorm =  tensor(0.0609, dtype=torch.float64)\n",
      "Iter  412 : loss =  tensor(1.7831)  gradnorm =  tensor(0.0597, dtype=torch.float64)\n",
      "Iter  413 : loss =  tensor(1.7147)  gradnorm =  tensor(0.0586, dtype=torch.float64)\n",
      "Iter  414 : loss =  tensor(1.6490)  gradnorm =  tensor(0.0574, dtype=torch.float64)\n",
      "Iter  415 : loss =  tensor(1.5857)  gradnorm =  tensor(0.0563, dtype=torch.float64)\n",
      "Iter  416 : loss =  tensor(1.5249)  gradnorm =  tensor(0.0552, dtype=torch.float64)\n",
      "Iter  417 : loss =  tensor(1.4664)  gradnorm =  tensor(0.0542, dtype=torch.float64)\n",
      "Iter  418 : loss =  tensor(1.4102)  gradnorm =  tensor(0.0531, dtype=torch.float64)\n",
      "Iter  419 : loss =  tensor(1.3561)  gradnorm =  tensor(0.0521, dtype=torch.float64)\n",
      "Iter  420 : loss =  tensor(1.3041)  gradnorm =  tensor(0.0511, dtype=torch.float64)\n",
      "Iter  421 : loss =  tensor(1.2541)  gradnorm =  tensor(0.0501, dtype=torch.float64)\n",
      "Iter  422 : loss =  tensor(1.2060)  gradnorm =  tensor(0.0491, dtype=torch.float64)\n",
      "Iter  423 : loss =  tensor(1.1597)  gradnorm =  tensor(0.0482, dtype=torch.float64)\n",
      "Iter  424 : loss =  tensor(1.1152)  gradnorm =  tensor(0.0472, dtype=torch.float64)\n",
      "Iter  425 : loss =  tensor(1.0724)  gradnorm =  tensor(0.0463, dtype=torch.float64)\n",
      "Iter  426 : loss =  tensor(1.0312)  gradnorm =  tensor(0.0454, dtype=torch.float64)\n",
      "Iter  427 : loss =  tensor(0.9916)  gradnorm =  tensor(0.0445, dtype=torch.float64)\n",
      "Iter  428 : loss =  tensor(0.9536)  gradnorm =  tensor(0.0437, dtype=torch.float64)\n",
      "Iter  429 : loss =  tensor(0.9170)  gradnorm =  tensor(0.0428, dtype=torch.float64)\n",
      "Iter  430 : loss =  tensor(0.8818)  gradnorm =  tensor(0.0420, dtype=torch.float64)\n",
      "Iter  431 : loss =  tensor(0.8479)  gradnorm =  tensor(0.0412, dtype=torch.float64)\n",
      "Iter  432 : loss =  tensor(0.8157)  gradnorm =  tensor(0.0409, dtype=torch.float64)\n",
      "Iter  433 : loss =  tensor(0.7840)  gradnorm =  tensor(0.0396, dtype=torch.float64)\n",
      "Iter  434 : loss =  tensor(0.7539)  gradnorm =  tensor(0.0388, dtype=torch.float64)\n",
      "Iter  435 : loss =  tensor(0.7249)  gradnorm =  tensor(0.0381, dtype=torch.float64)\n",
      "Iter  436 : loss =  tensor(0.6970)  gradnorm =  tensor(0.0373, dtype=torch.float64)\n",
      "Iter  437 : loss =  tensor(0.6702)  gradnorm =  tensor(0.0366, dtype=torch.float64)\n",
      "Iter  438 : loss =  tensor(0.6444)  gradnorm =  tensor(0.0359, dtype=torch.float64)\n",
      "Iter  439 : loss =  tensor(0.6197)  gradnorm =  tensor(0.0352, dtype=torch.float64)\n",
      "Iter  440 : loss =  tensor(0.5959)  gradnorm =  tensor(0.0345, dtype=torch.float64)\n",
      "Iter  441 : loss =  tensor(0.5729)  gradnorm =  tensor(0.0338, dtype=torch.float64)\n",
      "Iter  442 : loss =  tensor(0.5509)  gradnorm =  tensor(0.0332, dtype=torch.float64)\n",
      "Iter  443 : loss =  tensor(0.5297)  gradnorm =  tensor(0.0325, dtype=torch.float64)\n",
      "Iter  444 : loss =  tensor(0.5092)  gradnorm =  tensor(0.0319, dtype=torch.float64)\n",
      "Iter  445 : loss =  tensor(0.4896)  gradnorm =  tensor(0.0313, dtype=torch.float64)\n",
      "Iter  446 : loss =  tensor(0.4707)  gradnorm =  tensor(0.0307, dtype=torch.float64)\n",
      "Iter  447 : loss =  tensor(0.4526)  gradnorm =  tensor(0.0301, dtype=torch.float64)\n",
      "Iter  448 : loss =  tensor(0.4351)  gradnorm =  tensor(0.0295, dtype=torch.float64)\n",
      "Iter  449 : loss =  tensor(0.4184)  gradnorm =  tensor(0.0289, dtype=torch.float64)\n",
      "Iter  450 : loss =  tensor(0.4023)  gradnorm =  tensor(0.0284, dtype=torch.float64)\n",
      "Iter  451 : loss =  tensor(0.3868)  gradnorm =  tensor(0.0278, dtype=torch.float64)\n",
      "Iter  452 : loss =  tensor(0.3718)  gradnorm =  tensor(0.0273, dtype=torch.float64)\n",
      "Iter  453 : loss =  tensor(0.3575)  gradnorm =  tensor(0.0267, dtype=torch.float64)\n",
      "Iter  454 : loss =  tensor(0.3437)  gradnorm =  tensor(0.0262, dtype=torch.float64)\n",
      "Iter  455 : loss =  tensor(0.3304)  gradnorm =  tensor(0.0257, dtype=torch.float64)\n",
      "Iter  456 : loss =  tensor(0.3176)  gradnorm =  tensor(0.0252, dtype=torch.float64)\n",
      "Iter  457 : loss =  tensor(0.3054)  gradnorm =  tensor(0.0247, dtype=torch.float64)\n",
      "Iter  458 : loss =  tensor(0.2936)  gradnorm =  tensor(0.0242, dtype=torch.float64)\n",
      "Iter  459 : loss =  tensor(0.2823)  gradnorm =  tensor(0.0238, dtype=torch.float64)\n",
      "Iter  460 : loss =  tensor(0.2714)  gradnorm =  tensor(0.0233, dtype=torch.float64)\n",
      "Iter  461 : loss =  tensor(0.2610)  gradnorm =  tensor(0.0228, dtype=torch.float64)\n",
      "Iter  462 : loss =  tensor(2.8542)  gradnorm =  tensor(2.8089, dtype=torch.float64)\n",
      "Iter  463 : loss =  tensor(79.3567)  gradnorm =  tensor(7.1585, dtype=torch.float64)\n",
      "Iter  464 : loss =  tensor(73.6881)  gradnorm =  tensor(1.8670, dtype=torch.float64)\n",
      "Iter  465 : loss =  tensor(27.7296)  gradnorm =  tensor(1.4478, dtype=torch.float64)\n",
      "Iter  466 : loss =  tensor(16.6391)  gradnorm =  tensor(0.1824, dtype=torch.float64)\n",
      "Iter  467 : loss =  tensor(15.9244)  gradnorm =  tensor(0.1785, dtype=torch.float64)\n",
      "Iter  468 : loss =  tensor(15.2401)  gradnorm =  tensor(0.1746, dtype=torch.float64)\n",
      "Iter  469 : loss =  tensor(14.5849)  gradnorm =  tensor(0.1708, dtype=torch.float64)\n",
      "Iter  470 : loss =  tensor(13.9575)  gradnorm =  tensor(0.1671, dtype=torch.float64)\n",
      "Iter  471 : loss =  tensor(13.3569)  gradnorm =  tensor(0.1634, dtype=torch.float64)\n",
      "Iter  472 : loss =  tensor(inf)  gradnorm =  tensor(nan, dtype=torch.float64)\n",
      "train correct: 0, train accuracy: 0.0\n",
      "test correct: 0, test accuracy: 0.0\n",
      "Iter  2 : loss =  tensor(0.6931)  gradnorm =  tensor(4.9710, dtype=torch.float64)\n",
      "Iter  3 : loss =  tensor(4.1168)  gradnorm =  tensor(4.9553, dtype=torch.float64)\n",
      "Iter  4 : loss =  tensor(7.1564)  gradnorm =  tensor(5.6662, dtype=torch.float64)\n",
      "Iter  5 : loss =  tensor(1.3167)  gradnorm =  tensor(4.6311, dtype=torch.float64)\n",
      "Iter  6 : loss =  tensor(0.3042)  gradnorm =  tensor(2.6153, dtype=torch.float64)\n",
      "Iter  7 : loss =  tensor(0.7675)  gradnorm =  tensor(3.1477, dtype=torch.float64)\n",
      "Iter  8 : loss =  tensor(0.6102)  gradnorm =  tensor(3.7255, dtype=torch.float64)\n",
      "Iter  9 : loss =  tensor(0.3731)  gradnorm =  tensor(2.9594, dtype=torch.float64)\n",
      "Iter  10 : loss =  tensor(0.2090)  gradnorm =  tensor(1.9489, dtype=torch.float64)\n",
      "Iter  11 : loss =  tensor(0.0870)  gradnorm =  tensor(0.8843, dtype=torch.float64)\n",
      "Iter  12 : loss =  tensor(0.1289)  gradnorm =  tensor(1.1771, dtype=torch.float64)\n",
      "Iter  13 : loss =  tensor(0.1033)  gradnorm =  tensor(0.9771, dtype=torch.float64)\n",
      "Iter  14 : loss =  tensor(2.3391)  gradnorm =  tensor(4.9477, dtype=torch.float64)\n",
      "Iter  15 : loss =  tensor(23.0904)  gradnorm =  tensor(6.5078, dtype=torch.float64)\n",
      "Iter  16 : loss =  tensor(46.1274)  gradnorm =  tensor(6.3808, dtype=torch.float64)\n",
      "Iter  17 : loss =  tensor(69.1398)  gradnorm =  tensor(6.3536, dtype=torch.float64)\n",
      "Iter  18 : loss =  tensor(92.1893)  gradnorm =  tensor(6.3451, dtype=torch.float64)\n",
      "Iter  19 : loss =  tensor(115.2895)  gradnorm =  tensor(6.3430, dtype=torch.float64)\n",
      "Iter  20 : loss =  tensor(138.4452)  gradnorm =  tensor(6.3437, dtype=torch.float64)\n",
      "Iter  21 : loss =  tensor(inf)  gradnorm =  tensor(nan, dtype=torch.float64)\n",
      "train correct: 0, train accuracy: 0.0\n",
      "test correct: 0, test accuracy: 0.0\n",
      "Iter  2 : loss =  tensor(5.6912)  gradnorm =  tensor(5.2616, dtype=torch.float64)\n",
      "Iter  3 : loss =  tensor(1.6961)  gradnorm =  tensor(2.7192, dtype=torch.float64)\n",
      "Iter  4 : loss =  tensor(3.3380)  gradnorm =  tensor(2.8784, dtype=torch.float64)\n",
      "Iter  5 : loss =  tensor(0.7773)  gradnorm =  tensor(3.0073, dtype=torch.float64)\n",
      "Iter  6 : loss =  tensor(0.8405)  gradnorm =  tensor(2.4282, dtype=torch.float64)\n",
      "Iter  7 : loss =  tensor(0.3560)  gradnorm =  tensor(1.1757, dtype=torch.float64)\n",
      "Iter  8 : loss =  tensor(0.7443)  gradnorm =  tensor(3.0401, dtype=torch.float64)\n",
      "Iter  9 : loss =  tensor(0.0344)  gradnorm =  tensor(0.0083, dtype=torch.float64)\n",
      "train correct: 12494, train accuracy: 0.9605597257614136\n",
      "test correct: 2065, test accuracy: 0.954692542552948\n",
      "Iter  2 : loss =  tensor(5.1586)  gradnorm =  tensor(5.1005, dtype=torch.float64)\n",
      "Iter  3 : loss =  tensor(0.3971)  gradnorm =  tensor(1.9614, dtype=torch.float64)\n",
      "Iter  4 : loss =  tensor(0.5888)  gradnorm =  tensor(2.3718, dtype=torch.float64)\n",
      "Iter  5 : loss =  tensor(0.6037)  gradnorm =  tensor(4.0103, dtype=torch.float64)\n",
      "Iter  6 : loss =  tensor(0.3609)  gradnorm =  tensor(0.8606, dtype=torch.float64)\n",
      "Iter  7 : loss =  tensor(0.2184)  gradnorm =  tensor(1.2039, dtype=torch.float64)\n",
      "Iter  8 : loss =  tensor(3.1231)  gradnorm =  tensor(3.8482, dtype=torch.float64)\n",
      "Iter  9 : loss =  tensor(4.4890)  gradnorm =  tensor(3.0695, dtype=torch.float64)\n",
      "Iter  10 : loss =  tensor(1.1396)  gradnorm =  tensor(2.5465, dtype=torch.float64)\n",
      "Iter  11 : loss =  tensor(5.2791)  gradnorm =  tensor(1.8626, dtype=torch.float64)\n",
      "Iter  12 : loss =  tensor(0.2164)  gradnorm =  tensor(0.0208, dtype=torch.float64)\n",
      "Iter  13 : loss =  tensor(0.2164)  gradnorm =  tensor(0.0208, dtype=torch.float64)\n",
      "Iter  14 : loss =  tensor(0.2164)  gradnorm =  tensor(0.0208, dtype=torch.float64)\n",
      "Iter  15 : loss =  tensor(0.2164)  gradnorm =  tensor(0.0208, dtype=torch.float64)\n",
      "Iter  16 : loss =  tensor(0.2164)  gradnorm =  tensor(0.0208, dtype=torch.float64)\n",
      "Iter  17 : loss =  tensor(0.2164)  gradnorm =  tensor(0.0208, dtype=torch.float64)\n",
      "Iter  18 : loss =  tensor(0.2164)  gradnorm =  tensor(0.0208, dtype=torch.float64)\n",
      "Iter  19 : loss =  tensor(0.2164)  gradnorm =  tensor(0.0208, dtype=torch.float64)\n",
      "Iter  20 : loss =  tensor(0.2164)  gradnorm =  tensor(0.0208, dtype=torch.float64)\n",
      "Iter  21 : loss =  tensor(0.2164)  gradnorm =  tensor(0.0208, dtype=torch.float64)\n",
      "Iter  22 : loss =  tensor(0.5540)  gradnorm =  tensor(0.7491, dtype=torch.float64)\n",
      "Iter  23 : loss =  tensor(inf)  gradnorm =  tensor(nan, dtype=torch.float64)\n",
      "train correct: 0, train accuracy: 0.0\n",
      "test correct: 0, test accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "W = torch.rand(np.shape(quad_train)[1],dtype=torch.float64)\n",
    "\n",
    "optimizers = (GradientDescent,Adam,Nesterov,LBFGS)\n",
    "name = [\"SGD\",\"Adam\",\"Nesterov\",\"LBFGS\"]\n",
    "k = 0\n",
    "i = 1\n",
    "for opt in optimizers:\n",
    "    args = {\n",
    "        \"lossfun\": loss_function,\n",
    "        \"gradfun\": loss_gradient,\n",
    "        \"w\": W,\n",
    "        \"maxit\": 500,\n",
    "        \"batchsize\": 20, \n",
    "        \"data\": quad_train,\n",
    "        \"stochastic\": True,\n",
    "    }\n",
    "    if (name[k] == \"LBFGS\"):\n",
    "        args[\"m\"] = 10\n",
    "        args[\"tol\"] = 1e-2\n",
    "\n",
    "    else:\n",
    "        args[\"alpha\"] = 1e-3\n",
    "    nest = LBFGS(loss_function, loss_gradient, W,maxit=5000,params=None, data=quad_train, batchsize=20, stochastic=True,m=10,tol=1e-2)\n",
    "    w_nest,it,lossvals,gradnormvals = nest.minimize()\n",
    "    eval_test_func(w_nest, quad_train, quad_test)\n",
    "    plt.subplot(4,2,i)\n",
    "    plt.plot(lossvals)\n",
    "    i+=1\n",
    "    plt.subplot(4,2,i)\n",
    "    plt.plot(gradnormvals)\n",
    "    i+=1\n",
    "    k+=1\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(lossvals)\n",
    "plt.show()\n",
    "plt.figure()\n",
    "plt.plot(gradnormvals)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
